by ChatGPT o4 mini high

下面是一个基于 Python（FastAPI）和纯 HTML/CSS/JavaScript 的自动生成短视频项目示例。

---

## 项目目录结构

```
auto_video_project/
├── backend/
│   ├── main.py
│   ├── video_generator.py
│   └── requirements.txt
├── frontend/
│   ├── index.html
│   ├── style.css
│   └── script.js
└── README.md
```

---

## 1. backend/requirements.txt

```text
fastapi
uvicorn[standard]
openai
python-dotenv
ffmpeg-python
aiofiles
pydantic
```

---

## 2. backend/video_generator.py

```python
import os
import uuid
import asyncio
from typing import List
import openai
import ffmpeg
from dotenv import load_dotenv

load_dotenv()
openai.api_key = os.getenv('OPENAI_API_KEY')

async def generate_scenes(prompt: str, output_dir: str, progress_callback):
    """
    根据用户提示生成一系列场景：文本、图像、语音。
    progress_callback(i, total, message) 用于回调进度。
    """
    # 1. 生成脚本文本（示例：拆分为多场景）
    resp = openai.ChatCompletion.create(
        model='gpt-4',
        messages=[{'role': 'system', 'content': '请将以下提示拆分成3个叙事场景，每个场景包含简短描述。'},
                  {'role': 'user', 'content': prompt}]
    )
    scenes = resp.choices[0].message.content.strip().split('\n')
    total = len(scenes)
    for i, scene in enumerate(scenes, 1):
        progress_callback(i, total, f"生成第 {i} 个场景脚本")
        # 文本到语音
        tts_resp = openai.Audio.speech.create(
            model='tts-1',
            input=scene
        )
        audio_path = os.path.join(output_dir, f"scene_{i}.mp3")
        with open(audio_path, 'wb') as f:
            f.write(tts_resp.audio)

        progress_callback(i, total, f"生成第 {i} 个场景图像")
        # 文本到图像
        img_resp = openai.Image.create(
            prompt=scene,
            n=1,
            size="512x512"
        )
        img_data = openai.util.download(img_resp.data[0].url)
        img_path = os.path.join(output_dir, f"scene_{i}.png")
        with open(img_path, 'wb') as f:
            f.write(img_data)

    progress_callback(total, total, "合成视频中...")
    # 合成视频
    clips = []
    for i in range(1, total+1):
        img_file = os.path.join(output_dir, f"scene_{i}.png")
        audio_file = os.path.join(output_dir, f"scene_{i}.mp3")
        clip = ffmpeg.input(img_file, loop=1, t=5)
        audio = ffmpeg.input(audio_file)
        clips.append(ffmpeg.concat(clip, audio, v=1, a=1).node)
    # 假设只有一个合并合成
    video = clips[0]
    out_path = os.path.join(output_dir, 'output.mp4')
    ffmpeg.output(video[0], video[1], out_path, vcodec='libx264', acodec='aac').overwrite_output().run()
    return out_path
```

---

## 3. backend/main.py

```python
import os
import shutil
import uuid
import threading
from fastapi import FastAPI, BackgroundTasks, UploadFile, Form
from fastapi.responses import FileResponse, JSONResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
from video_generator import generate_scenes

app = FastAPI()
app.mount('/static', StaticFiles(directory='../frontend'), name='static')

TASKS = {}

class GenerateRequest(BaseModel):
    prompt: str

@app.post('/api/generate')
async def generate(req: GenerateRequest, background_tasks: BackgroundTasks):
    task_id = str(uuid.uuid4())
    out_dir = os.path.join('temp', task_id)
    os.makedirs(out_dir, exist_ok=True)
    TASKS[task_id] = {'status': 'pending', 'progress': 0, 'message': ''}

    def progress_cb(i, total, msg):
        TASKS[task_id]['progress'] = int(i/total*100)
        TASKS[task_id]['message'] = msg
        TASKS[task_id]['status'] = 'running' if i < total else 'completed'

    def task():
        try:
            video_path = asyncio.run(generate_scenes(req.prompt, out_dir, progress_cb))
            TASKS[task_id]['video'] = video_path
        except Exception as e:
            TASKS[task_id]['status'] = 'error'
            TASKS[task_id]['message'] = str(e)

    threading.Thread(target=task).start()
    return {'task_id': task_id}

@app.get('/api/status/{task_id}')
async def status(task_id: str):
    task = TASKS.get(task_id)
    if not task:
        return JSONResponse({'error': 'not found'}, status_code=404)
    return task

@app.get('/api/video/{task_id}')
async def get_video(task_id: str):
    task = TASKS.get(task_id)
    if not task or task.get('status') != 'completed':
        return JSONResponse({'error': 'not ready'}, status_code=404)
    return FileResponse(task['video'], media_type='video/mp4')
```

---

## 4. frontend/index.html

```html
<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="style.css">
  <title>自动生成短视频</title>
</head>
<body>
  <div class="container">
    <h1>自动生成短视频</h1>
    <textarea id="prompt" placeholder="输入场景提示词..."></textarea>
    <button id="generate">开始生成</button>
    <div id="progressContainer" hidden>
      <div id="progressBar"></div>
      <p id="progressText"></p>
    </div>
    <video id="player" controls hidden></video>
  </div>
  <script src="script.js"></script>
</body>
</html>
```

---

## 5. frontend/style.css

```css
body { font-family: sans-serif; background: #f5f5f5; margin: 0; padding: 0; }
.container { max-width: 600px; margin: 40px auto; background: #fff; padding: 20px; border-radius: 8px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); }
textarea { width: 100%; height: 100px; margin-bottom: 10px; }
button { padding: 10px 20px; font-size: 16px; cursor: pointer; }
#progressContainer { margin-top: 20px; }
#progressBar { width: 0%; height: 20px; background: #4caf50; border-radius: 4px; transition: width 0.3s; }
video { width: 100%; margin-top: 20px; }
```

---

## 6. frontend/script.js

```javascript
const generateBtn = document.getElementById('generate');
const promptEl = document.getElementById('prompt');
const progressContainer = document.getElementById('progressContainer');
const progressBar = document.getElementById('progressBar');
const progressText = document.getElementById('progressText');
const player = document.getElementById('player');

generateBtn.addEventListener('click', async () => {
  const prompt = promptEl.value.trim();
  if (!prompt) return;
  generateBtn.disabled = true;
  progressContainer.hidden = false;
  player.hidden = true;

  const resp = await fetch('/api/generate', {
    method: 'POST',
    headers: {'Content-Type': 'application/json'},
    body: JSON.stringify({ prompt })
  });
  const { task_id } = await resp.json();

  const check = setInterval(async () => {
    const status = await fetch(`/api/status/${task_id}`).then(r => r.json());
    progressBar.style.width = status.progress + '%';
    progressText.textContent = status.message;
    if (status.status === 'completed') {
      clearInterval(check);
      player.src = `/api/video/${task_id}`;
      player.hidden = false;
      generateBtn.disabled = false;
    }
    if (status.status === 'error') {
      clearInterval(check);
      progressText.textContent = '生成出错: ' + status.message;
      generateBtn.disabled = false;
    }
  }, 1000);
});
```

---

## 7. README.md

```markdown
# 自动生成短视频项目

## 功能说明

- 输入提示词，系统自动生成分场景脚本。
- 对每个场景调用 OpenAI 文本、语音、图像生成 API。
- 使用 FFmpeg 合并图像与音频，输出 MP4 视频。
- 前端显示生成进度，并可在线播放。

## 启动方式

1. 安装依赖：

```bash
pip install -r backend/requirements.txt
```

2. 设置环境变量 `OPENAI_API_KEY`。

3. 启动后端服务：

```bash
cd backend
uvicorn main:app --reload
```

4. 打开浏览器访问 `http://localhost:8000/static/index.html`
```

---

这样即可得到一个完整的自动生成短视频的网页版示例项目。

